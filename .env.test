# Crane AI Agent Runtime - Testing Environment Configuration
#
# This configuration enables local LLM testing without OpenAI API dependency.
# For detailed setup instructions, see: claudedocs/local_llm_testing_guide.md

# ==============================================================================
# Local LLM Configuration (via LiteLLM Proxy)
# ==============================================================================

# Point to local LiteLLM proxy (uncomment to use local LLM)
# OPENAI_BASE_URL=http://localhost:4000
# OPENAI_MODEL=qwen2.5:3b
# OPENAI_TEMPERATURE=0.1
# Note: OPENAI_API_KEY is automatically set to dummy value when OPENAI_BASE_URL is set

# Or use OpenAI for testing (requires API key)
# OPENAI_API_KEY=sk-your-key-here
# OPENAI_MODEL=gpt-4o-mini

# ==============================================================================
# Application Configuration
# ==============================================================================

ENVIRONMENT=test
DEBUG=true
LOG_LEVEL=DEBUG

# Use in-memory database for tests
DATABASE_URL=sqlite:///:memory:

# Disable external services for tests
CACHE_ENABLED=false
EXTERNAL_API_URL=http://localhost:8888/mock-api
MOCK_EXTERNAL_SERVICES=true

# Test-specific settings
TEST_TIMEOUT=30
TEST_PARALLEL=true
TEST_COVERAGE=true

# Security (use test keys only)
SECRET_KEY=test-secret-key-not-for-production
JWT_SECRET=test-jwt-secret

# Disable rate limiting for tests
RATE_LIMIT_ENABLED=false

# Disable monitoring for tests
METRICS_ENABLED=false
TRACING_ENABLED=false
